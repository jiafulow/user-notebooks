{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6444d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble (system)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "  raise AssertionError('Please run this notebook with Python 3.')\n",
    "\n",
    "# Preamble (tools)\n",
    "import numpy as np\n",
    "import collections\n",
    "import contextlib\n",
    "import functools\n",
    "import itertools\n",
    "import more_itertools\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Preamble (ML)\n",
    "np.random.seed(2027)  # set random seed\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2027)  # set random seed\n",
    "\n",
    "import dask\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaccc0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Using cmssw      : CMSSW_11_1_7\n",
      "[INFO    ] Using python     : 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]\n",
      "[INFO    ] Using numpy      : 1.20.3\n",
      "[INFO    ] Using matplotlib : 3.4.2\n",
      "[INFO    ] Using tensorflow : 2.6.0\n",
      "[INFO    ] Using keras      : 2.6.0\n",
      "2021-10-17 01:37:48.190217: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "[INFO    ] .. list devices  : [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "2021-10-17 01:37:48.190263: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login1.ufhpc): /proc/driver/nvidia/version does not exist\n",
      "[INFO    ] Using dask       : 2021.08.1\n",
      "[INFO    ] Using emtf-nnet  : 0.0.2-dev\n"
     ]
    }
   ],
   "source": [
    "# Preamble (EMTF)\n",
    "from emtf_nbtools import get_logger, get_colormap, emtf_nbtools\n",
    "\n",
    "try:\n",
    "  import emtf_nnet\n",
    "except ImportError:\n",
    "  raise ImportError('Could not import emtf_nnet. It can be found at '\n",
    "                    'https://github.com/jiafulow/emtf-nnet')\n",
    "\n",
    "# Get plot style and color map\n",
    "plt.style.use('tdrstyle.mplstyle')\n",
    "cm = get_colormap()\n",
    "\n",
    "# Get logger\n",
    "logger = get_logger()\n",
    "logger.info('Using cmssw      : {}'.format(os.environ.get('CMSSW_VERSION', 'N/A')))\n",
    "logger.info('Using python     : {}'.format(sys.version.replace('\\n', '')))\n",
    "logger.info('Using numpy      : {}'.format(np.__version__))\n",
    "logger.info('Using matplotlib : {}'.format(matplotlib.__version__))\n",
    "logger.info('Using tensorflow : {}'.format(tf.__version__))\n",
    "logger.info('Using keras      : {}'.format(tf.keras.__version__))\n",
    "logger.info('.. list devices  : {}'.format(tf.config.list_physical_devices()))\n",
    "logger.info('Using dask       : {}'.format(dask.__version__))\n",
    "logger.info('Using emtf-nnet  : {}'.format(emtf_nnet.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0167506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Using settings   : |\n",
      "[INFO    ] .. zone          : 0\n",
      "[INFO    ] .. timezone      : 0\n",
      "[INFO    ] .. maxevents     : 100\n",
      "[INFO    ] .. workers       : 1\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "# zone: (0,1,2) -> eta=(1.98..2.5, 1.55..1.98, 1.2..1.55)\n",
    "zone = 0\n",
    "#zone = 1\n",
    "#zone = 2\n",
    "\n",
    "# timezone: (0,1,2) -> BX=(0,-1,-2)\n",
    "timezone = 0\n",
    "\n",
    "maxevents = 100\n",
    "#maxevents = -1\n",
    "\n",
    "workers = 1\n",
    "#workers = 8\n",
    "\n",
    "# Input files\n",
    "signal_fname = 'signal.210922.npz'\n",
    "signal_dxy_fname = 'signal_dxy.210922.npz'\n",
    "bkgnd_fname = 'bkgnd.210922.npz'\n",
    "\n",
    "# Model files\n",
    "patterns_fname = 'patterns_zone%i.npz' % zone\n",
    "nnet_model_fname = 'quant_nnet_model.json'\n",
    "\n",
    "logger.info('Using settings   : |')\n",
    "logger.info('.. zone          : {}'.format(zone))\n",
    "logger.info('.. timezone      : {}'.format(timezone))\n",
    "logger.info('.. maxevents     : {}'.format(maxevents))\n",
    "logger.info('.. workers       : {}'.format(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c1055b",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f37137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signal(fname):\n",
    "  logger.info('Loading from {}'.format(fname))\n",
    "  with np.load(fname) as loaded:\n",
    "    out_part = loaded['out_part']\n",
    "    out_hits_values = loaded['out_hits_values']\n",
    "    out_hits_row_splits = loaded['out_hits_row_splits']\n",
    "    out_hits_shape = (out_hits_row_splits.shape[0] - 1,) + (None,) + out_hits_values.shape[1:]\n",
    "    out_simhits_values = loaded['out_simhits_values']\n",
    "    out_simhits_row_splits = loaded['out_simhits_row_splits']\n",
    "    out_simhits_shape = (out_simhits_row_splits.shape[0] - 1,) + (None,) + out_simhits_values.shape[1:]\n",
    "  logger.info('out_part: {}, out_hits: {}, out_simhits: {}'.format(\n",
    "      (out_part.shape, out_part.dtype.name),\n",
    "      (out_hits_shape, out_hits_values.dtype.name),\n",
    "      (out_simhits_shape, out_simhits_values.dtype.name)))\n",
    "  return (out_part, (out_hits_values, out_hits_row_splits), (out_simhits_values, out_simhits_row_splits))\n",
    "\n",
    "\n",
    "def load_bkgnd(fname):\n",
    "  logger.info('Loading from {}'.format(fname))\n",
    "  with np.load(fname) as loaded:\n",
    "    bkg_aux = loaded['out_aux']\n",
    "    bkg_hits_values = loaded['out_hits_values']\n",
    "    bkg_hits_row_splits = loaded['out_hits_row_splits']\n",
    "    bkg_hits_shape = (bkg_hits_row_splits.shape[0] - 1,) + (None,) + bkg_hits_values.shape[1:]\n",
    "  logger.info('bkg_aux: {} bkg_hits: {}'.format(\n",
    "      (bkg_aux.shape, bkg_aux.dtype.name),\n",
    "      (bkg_hits_shape, bkg_hits_values.dtype.name)))\n",
    "  return (bkg_aux, (bkg_hits_values, bkg_hits_row_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912170d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading from signal.210922.npz\n",
      "[INFO    ] out_part: ((2000000, 10), 'float32'), out_hits: ((2000000, None, 17), 'int32'), out_simhits: ((2000000, None, 17), 'int32')\n",
      "[INFO    ] Loading from bkgnd.210922.npz\n",
      "[INFO    ] bkg_aux: ((12592764, 2), 'int32') bkg_hits: ((12592764, None, 17), 'int32')\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "out_part, out_hits, out_simhits = load_signal(signal_fname)\n",
    "\n",
    "bkg_aux, bkg_hits = load_bkgnd(bkgnd_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74b51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternHelper(object):\n",
    "  \"\"\"Reshapes patterns for use in NN.\"\"\"\n",
    "  def get_reshaped_patterns(self, patterns):\n",
    "    patterns = patterns[3]  # prompt patterns only\n",
    "    patterns = patterns[[3, 2, 4, 1, 5, 0, 6]]  # ordered by straightness\n",
    "    return patterns  # shape is (7, 8, 3)\n",
    "\n",
    "  def get_reshaped_patt_filters(self, patt_filters):\n",
    "    patt_filters = patt_filters[3]  # prompt patterns only\n",
    "    patt_filters = patt_filters[[3, 2, 4, 1, 5, 0, 6]]  # ordered by straightness\n",
    "    patt_filters = np.transpose(patt_filters, [3, 2, 1, 0])  # kernel shape is HWCD\n",
    "    return patt_filters  # shape is (1, 111, 8, 7)\n",
    "\n",
    "  def get_reshaped_patt_activations(self, patt_activations):\n",
    "    patt_activations = patt_activations // 4  # from 8-bit to 6-bit\n",
    "    po2_coeffs = (2 ** np.arange(8))  # [1,2,4,8,16,32,64,128]\n",
    "    patt_activations[0] = 0           # set to zero if empty hit\n",
    "    patt_activations[po2_coeffs] = 0  # set to zero if single hit\n",
    "    assert patt_activations.max() == (64 - 1)\n",
    "    return patt_activations  # shape is (256,)\n",
    "\n",
    "\n",
    "def load_patterns():\n",
    "  num_emtf_zones = 3\n",
    "  helper = PatternHelper()\n",
    "\n",
    "  patterns = []\n",
    "  patt_filters = []\n",
    "  patt_activations = []\n",
    "  for z in range(num_emtf_zones):\n",
    "    fname = patterns_fname.replace('zone%i' % zone, 'zone%i' % z)  # modify filename\n",
    "    logger.info('Loading from {}'.format(fname))\n",
    "    with np.load(fname) as loaded:\n",
    "      patterns.append(helper.get_reshaped_patterns(loaded['patterns']))\n",
    "      patt_filters.append(helper.get_reshaped_patt_filters(loaded['patt_filters']))\n",
    "      patt_activations.append(helper.get_reshaped_patt_activations(loaded['patt_activations']))\n",
    "\n",
    "  patterns = np.asarray(patterns)\n",
    "  patt_filters = np.asarray(patt_filters)\n",
    "  patt_activations = np.asarray(patt_activations)\n",
    "  logger.info('patterns: {} patt_filters: {} patt_activations: {}'.format(\n",
    "      patterns.shape, patt_filters.shape, patt_activations.shape))\n",
    "\n",
    "  # Dump constants\n",
    "  pattern_bank = emtf_nnet.keras.utils.PatternBank(patterns, patt_filters, patt_activations)\n",
    "  emtf_nnet.keras.utils.save_pattern_bank(pattern_bank)  # write to file\n",
    "  loaded_pattern_bank = emtf_nnet.keras.utils.load_pattern_bank('pattern_bank.json')\n",
    "  return loaded_pattern_bank\n",
    "\n",
    "\n",
    "def load_nnet_model():\n",
    "  from emtf_nnet.keras.quantization import default_quantize_scheme\n",
    "  path = nnet_model_fname\n",
    "  w_path = path.replace('.json', '_weights.h5')\n",
    "  custom_objects = default_quantize_scheme.DefaultQuantizeScheme._QUANTIZATION_OBJECTS\n",
    "  logger.info('Loading from {}'.format(path))\n",
    "  loaded_nnet_model = emtf_nnet.keras.utils.load_nnet_model(path, w_path, custom_objects)\n",
    "  loaded_nnet_model.trainable = False\n",
    "  logger.info('NN model: {}'.format(loaded_nnet_model.name))\n",
    "\n",
    "  # Make sure all the tensors are computed\n",
    "  input_shape = loaded_nnet_model.inputs[0].shape\n",
    "  _ = loaded_nnet_model(np.random.random_sample((1,) + input_shape[1:]))\n",
    "  # Dump weights\n",
    "  weights = [\n",
    "    #FIXME: hardcoded dequantizer\n",
    "    loaded_nnet_model.get_layer('quant_preprocessing').layer.scale.numpy() * np.power(2., 10),\n",
    "    np.zeros(loaded_nnet_model.inputs[0].shape[-1], dtype=np.float32),\n",
    "    loaded_nnet_model.get_layer('quant_dense').layer.folded_kernel.numpy() * np.power(2., 6),\n",
    "    loaded_nnet_model.get_layer('quant_dense').layer.folded_bias.numpy() * np.power(2., 6),\n",
    "    loaded_nnet_model.get_layer('quant_dense_1').layer.folded_kernel.numpy() * np.power(2., 6),\n",
    "    loaded_nnet_model.get_layer('quant_dense_1').layer.folded_bias.numpy() * np.power(2., 6),\n",
    "    loaded_nnet_model.get_layer('quant_dense_2').layer.folded_kernel.numpy() * np.power(2., 6),\n",
    "    loaded_nnet_model.get_layer('quant_dense_2').layer.folded_bias.numpy() * np.power(2., 6),\n",
    "    loaded_nnet_model.get_layer('quant_dense_final').layer.folded_kernel.numpy().squeeze() * np.power(2., 9),\n",
    "    np.zeros(loaded_nnet_model.outputs[0].shape[-1], dtype=np.float32),\n",
    "  ]\n",
    "  emtf_nnet.keras.utils.save_serializable_object(weights, 'nnet_weights.json')  # write to file\n",
    "  return loaded_nnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c38c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading from patterns_zone0.npz\n",
      "[INFO    ] Loading from patterns_zone1.npz\n",
      "[INFO    ] Loading from patterns_zone2.npz\n",
      "[INFO    ] patterns: (3, 7, 8, 3) patt_filters: (3, 1, 111, 8, 7) patt_activations: (3, 256)\n",
      "[INFO    ] Loading from quant_nnet_model.json\n",
      "2021-10-17 01:37:59.943058: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[INFO    ] NN model: quant_nnet_model\n"
     ]
    }
   ],
   "source": [
    "# Load pattern bank, NN model\n",
    "loaded_pattern_bank = load_patterns()\n",
    "\n",
    "loaded_nnet_model = load_nnet_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c4c88",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816d2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "from emtf_nnet.architecture import endless_v3\n",
    "\n",
    "tf.config.optimizer.set_jit(True)  # enable XLA\n",
    "#tf.config.threading.set_inter_op_parallelism_threads(32)\n",
    "#tf.config.threading.set_intra_op_parallelism_threads(32)\n",
    "\n",
    "endless_v3.set_pattern_bank(loaded_pattern_bank)\n",
    "endless_v3.set_nnet_model(loaded_nnet_model)\n",
    "config = endless_v3.configure()\n",
    "endless_v3.set_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff8accd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] sector_part: (1889907, 10) sector_hits: (1889907, None, 17) sector_simhits: (1889907, None, 17)\n"
     ]
    }
   ],
   "source": [
    "# Create inputs\n",
    "sector_part, sector_hits, sector_simhits = endless_v3.create_sector_hits(out_part, out_hits, out_simhits)\n",
    "out_part, out_hits, out_simhits = None, None, None  # not needed anymore\n",
    "\n",
    "logger.info('sector_part: {} sector_hits: {} sector_simhits: {}'.format(\n",
    "    sector_part.shape, sector_hits.shape, sector_simhits.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6802454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] sector_noises_aux: (4520660, 2) sector_noises: (4520660, None, 17)\n"
     ]
    }
   ],
   "source": [
    "sector_noises_aux, sector_noises = endless_v3.create_sector_noises(bkg_aux, bkg_hits)\n",
    "bkg_aux, bkg_hits = None, None  # not needed anymore\n",
    "\n",
    "logger.info('sector_noises_aux: {} sector_noises: {}'.format(\n",
    "    sector_noises_aux.shape, sector_noises.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640d6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "datagen_sparse = endless_v3.get_datagen_sparse(sector_hits, batch_size=batch_size)\n",
    "try:\n",
    "  x_test_sparse = datagen_sparse[0]\n",
    "except:\n",
    "  raise ValueError('Fail to get data from datagen_sparse.')\n",
    "\n",
    "datagen = endless_v3.get_datagen(sector_hits, batch_size=batch_size)\n",
    "try:\n",
    "  x_test = datagen[0]\n",
    "except:\n",
    "  raise ValueError('Fail to get data from datagen.')\n",
    "\n",
    "datagen_noise = endless_v3.get_datagen_shuffle(sector_noises, batch_size=batch_size)\n",
    "try:\n",
    "  x_test_noise = datagen_noise[0]\n",
    "except:\n",
    "  raise ValueError('Fail to get data from datagen_noise.')\n",
    "\n",
    "assert isinstance(x_test_sparse, np.ndarray) and len(x_test_sparse) == batch_size\n",
    "assert isinstance(x_test, np.ndarray) and len(x_test) == batch_size and x_test.ndim == 4\n",
    "assert isinstance(x_test_noise, np.ndarray) and len(x_test_noise) == batch_size and x_test_noise.ndim == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3d3992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  22,    0,  1944,   -4,   61,    0,    6,    9,    0,    1,    6,    1,    0,   -1,    1],\n",
      " [  30,    0,  1928,    0,   61,    0,    6,   10,    0,    1,    4,    1,    0,    0,    1],\n",
      " [  31,    0,  1928,    0,   61,    0,    6,   10,    0,    1,    4,    0,    0,    0,    1],\n",
      " [  39,    0,  1932,    0,   61,    0,    6,   10,    0,    1,    4,    1,    0,    0,    1],\n",
      " [  40,    0,  1932,    0,   61,    0,    6,   10,    0,    1,    4,    0,    0,    0,    1],\n",
      " [  58,    0,  1994,    0,   56,    0,    0,    0,    0,    3,    4,    1,    1,    0,    1],\n",
      " [  76,    0,  1948,    0,   66,    0,    0,    0,    1,    1,    4,    1,    1,    0,    1],\n",
      " [  85,    0,  1948,    0,   60,    0,    0,    0,   -1,    1,    4,    0,    1,    0,    1],\n",
      " [  94,    0,  1929,    0,   64,    0,    0,    0,    0,    1,    4,    0,    1,    0,    1]]\n",
      "[[   0,    0,  1697,    0,    9,    0,    6,   10,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  18,    0,  1800,    4,    9,    0,    6,    8,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  27,    0,  1848,    4,    9,    0,    6,    8,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  36,    0,  1856,    0,    9,    0,    6,   10,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  72,    0,  1792,    0,    7,    0,    0,    0,    0,    4,    4,    1,    1,    0,    1],\n",
      " [  81,    0,  1857,    0,    9,    0,    0,    0,    1,    4,    4,    0,    1,    0,    1],\n",
      " [ 108,    0,  1643,   10,   12,    0,    5,    0,    0,    4,    4,    0,    0,    0,    1]]\n",
      "[[  14,    0,  4628,    4,   63,    0,    6,    8,    0,    1,    4,    1,    0,    0,    1],\n",
      " [  26,    0,  4696,    0,   62,    0,    6,   10,    0,    1,    4,    1,    0,    0,    1],\n",
      " [  35,    0,  4700,    0,   61,    0,    6,   10,    0,    1,    4,    0,    0,    0,    1],\n",
      " [  44,    0,  4693,    0,   61,    0,    6,   10,    0,    1,    4,    0,    0,    0,    1],\n",
      " [  68,    0,  4639,    0,   56,    0,    0,    0,    0,    3,    4,    1,    1,    0,    1],\n",
      " [  80,    0,  4686,    0,   66,    0,    0,    0,    1,    1,    4,    1,    1,    0,    1],\n",
      " [  89,    0,  4695,    0,   60,    0,    0,    0,    1,    1,    4,    0,    1,    0,    1],\n",
      " [  98,    0,  4686,    0,   64,    0,    0,    0,   -1,    1,    4,    0,    1,    0,    1]]\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "my_array2string = functools.partial(\n",
    "    np.array2string, separator=', ', max_line_width=100, formatter={'int': (lambda x: '% 4d' % x)})\n",
    "\n",
    "print(my_array2string(x_test_sparse[0]))\n",
    "print(my_array2string(x_test_sparse[1]))\n",
    "print(my_array2string(x_test_sparse[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2746e03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 115, 2, 13)\n",
      "[[ 1944,   -4,   61,    0,    6,    9,    0,    1,    6,    1,    0,   -1,    1],\n",
      " [ 1928,    0,   61,    0,    6,   10,    0,    1,    4,    1,    0,    0,    1],\n",
      " [ 1928,    0,   61,    0,    6,   10,    0,    1,    4,    0,    0,    0,    1],\n",
      " [ 1932,    0,   61,    0,    6,   10,    0,    1,    4,    1,    0,    0,    1],\n",
      " [ 1932,    0,   61,    0,    6,   10,    0,    1,    4,    0,    0,    0,    1],\n",
      " [ 1994,    0,   56,    0,    0,    0,    0,    3,    4,    1,    1,    0,    1],\n",
      " [ 1948,    0,   66,    0,    0,    0,    1,    1,    4,    1,    1,    0,    1],\n",
      " [ 1948,    0,   60,    0,    0,    0,   -1,    1,    4,    0,    1,    0,    1],\n",
      " [ 1929,    0,   64,    0,    0,    0,    0,    1,    4,    0,    1,    0,    1]]\n",
      "[[ 1697,    0,    9,    0,    6,   10,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 1800,    4,    9,    0,    6,    8,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 1848,    4,    9,    0,    6,    8,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 1856,    0,    9,    0,    6,   10,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 1792,    0,    7,    0,    0,    0,    0,    4,    4,    1,    1,    0,    1],\n",
      " [ 1857,    0,    9,    0,    0,    0,    1,    4,    4,    0,    1,    0,    1],\n",
      " [ 1643,   10,   12,    0,    5,    0,    0,    4,    4,    0,    0,    0,    1]]\n",
      "[[ 4628,    4,   63,    0,    6,    8,    0,    1,    4,    1,    0,    0,    1],\n",
      " [ 4696,    0,   62,    0,    6,   10,    0,    1,    4,    1,    0,    0,    1],\n",
      " [ 4700,    0,   61,    0,    6,   10,    0,    1,    4,    0,    0,    0,    1],\n",
      " [ 4693,    0,   61,    0,    6,   10,    0,    1,    4,    0,    0,    0,    1],\n",
      " [ 4639,    0,   56,    0,    0,    0,    0,    3,    4,    1,    1,    0,    1],\n",
      " [ 4686,    0,   66,    0,    0,    0,    1,    1,    4,    1,    1,    0,    1],\n",
      " [ 4695,    0,   60,    0,    0,    0,    1,    1,    4,    0,    1,    0,    1],\n",
      " [ 4686,    0,   64,    0,    0,    0,   -1,    1,    4,    0,    1,    0,    1]]\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "isvalid = lambda x: (x[..., -1] != 0)  # x[..., -1] is the valid flag\n",
    "\n",
    "print(x_test.shape)\n",
    "print(my_array2string(x_test[0][isvalid(x_test[0])]))\n",
    "print(my_array2string(x_test[1][isvalid(x_test[1])]))\n",
    "print(my_array2string(x_test[2][isvalid(x_test[2])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571a875",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12b219ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "Model: \"endless_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 115, 2, 13)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zoning_0 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zoning_1 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zoning_2 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pooling_0 (Pooling)             ((None, 288), (None, 6272        zoning_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooling_1 (Pooling)             ((None, 288), (None, 6272        zoning_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooling_2 (Pooling)             ((None, 288), (None, 6272        zoning_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "suppression_0 (Suppression)     ((None, 288), (None, 0           pooling_0[0][0]                  \n",
      "                                                                 pooling_0[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "suppression_1 (Suppression)     ((None, 288), (None, 0           pooling_1[0][0]                  \n",
      "                                                                 pooling_1[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "suppression_2 (Suppression)     ((None, 288), (None, 0           pooling_2[0][0]                  \n",
      "                                                                 pooling_2[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "zonesorting_0 (ZoneSorting)     ((None, 4), (None, 4 0           suppression_0[0][0]              \n",
      "                                                                 suppression_0[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "zonesorting_1 (ZoneSorting)     ((None, 4), (None, 4 0           suppression_1[0][0]              \n",
      "                                                                 suppression_1[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "zonesorting_2 (ZoneSorting)     ((None, 4), (None, 4 0           suppression_2[0][0]              \n",
      "                                                                 suppression_2[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_0 (Concatenate)     (None, 12)           0           zonesorting_0[0][0]              \n",
      "                                                                 zonesorting_1[0][0]              \n",
      "                                                                 zonesorting_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12)           0           zonesorting_0[0][1]              \n",
      "                                                                 zonesorting_1[0][1]              \n",
      "                                                                 zonesorting_2[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12)           0           zonesorting_0[0][2]              \n",
      "                                                                 zonesorting_1[0][2]              \n",
      "                                                                 zonesorting_2[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "zonemerging_0 (ZoneMerging)     ((None, 4), (None, 4 0           concatenate_0[0][0]              \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "trkbuilding_0 (TrkBuilding)     ((None, 4, 40), (Non 0           inputs[0][0]                     \n",
      "                                                                 zonemerging_0[0][0]              \n",
      "                                                                 zonemerging_0[0][1]              \n",
      "                                                                 zonemerging_0[0][2]              \n",
      "                                                                 zonemerging_0[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "duperemoval_0 (DupeRemoval)     ((None, 4, 40), (Non 0           trkbuilding_0[0][0]              \n",
      "                                                                 trkbuilding_0[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "trainfilter_0 (TrainFilter)     ((None, 4, 40), (Non 0           duperemoval_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fullyconnect_0 (FullyConnect)   ((None, 4, 40), (Non 2577        trainfilter_0[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,393\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,393\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = endless_v3.create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0855c0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 01:38:29.542213: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-17 01:38:32.401599: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x2b69200a4080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-10-17 01:38:32.401636: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Host, Default Version\n",
      "2021-10-17 01:38:32.718306: I tensorflow/compiler/jit/xla_compilation_cache.cc:363] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2021-10-17 01:38:33.247211: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "[INFO    ] outputs: ((100, 4, 40), 'int32')\n",
      "[INFO    ] outputs: ((100, 4, 12), 'int32')\n",
      "[INFO    ] outputs: ((100, 4, 1), 'bool')\n",
      "[INFO    ] outputs: ((100, 4, 1), 'float32')\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "num_test_samples = x_test.shape[0] if maxevents == -1 else maxevents\n",
    "x_test_1 = x_test[:num_test_samples]\n",
    "x_test_sparse_1 = x_test_sparse[:num_test_samples]\n",
    "\n",
    "outputs = model.predict(x_test_1, workers=workers, use_multiprocessing=False)  # now wait...\n",
    "if isinstance(outputs, tuple):\n",
    "  for i in range(len(outputs)):\n",
    "    logger.info('outputs: {}'.format((outputs[i].shape, outputs[i].dtype.name)))\n",
    "else:\n",
    "  logger.info('outputs: {}'.format((outputs.shape, outputs.dtype.name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d9a06dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[999999 999999     16 ...     61     61      0]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]]\n",
      "\n",
      " [[   -87 999999     16 ...      7     63      0]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]]\n",
      "\n",
      " [[999999    -52     16 ...     61     63      0]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   -69 999999     16 ...     12     63      0]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]]\n",
      "\n",
      " [[   113 999999 999999 ...     23     62      0]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]]\n",
      "\n",
      " [[  -340 999999      8 ...     30     63      0]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]\n",
      "  [999999 999999 999999 ... 999999 999999 999999]]] [[[230 230  44 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]]\n",
      "\n",
      " [[  0 230  36 ... 230 144 216]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]]\n",
      "\n",
      " [[230  28  52 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0 230  36 ... 230 144 216]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]]\n",
      "\n",
      " [[ 90 230 230 ... 198 204 228]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]]\n",
      "\n",
      " [[  4 230  38 ... 112 146 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]\n",
      "  [230 230 230 ... 230 230 230]]] [[ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [ True False False False]] [[ 0.14123535  0.07714844  0.07714844  0.07714844]\n",
      " [-0.21154785  0.07714844  0.07714844  0.07714844]\n",
      " [-0.18530273  0.07714844  0.07714844  0.07714844]\n",
      " [-0.10473633  0.07714844  0.07714844  0.07714844]\n",
      " [-0.3284912   0.07714844  0.07714844  0.07714844]\n",
      " [-0.29467773  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.04333496  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.06335449  0.07714844  0.07714844  0.07714844]\n",
      " [-0.10620117  0.07714844  0.07714844  0.07714844]\n",
      " [-0.3116455   0.07714844  0.07714844  0.07714844]\n",
      " [-0.01550293  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.23010254  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.44213867  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.3236084   0.07714844  0.07714844  0.07714844]\n",
      " [-0.36083984  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.06762695  0.07714844  0.07714844  0.07714844]\n",
      " [-0.45495605  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.2869873   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.3942871   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.12133789  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.2241211   0.07714844  0.07714844  0.07714844]\n",
      " [-0.03857422  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.22033691  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.11328125  0.07714844  0.07714844  0.07714844]\n",
      " [-0.34179688  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.0748291   0.399292    0.07714844  0.07714844]\n",
      " [ 0.34545898  0.07714844  0.07714844  0.07714844]\n",
      " [-0.1282959   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.42419434  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.16552734  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.01196289  0.07714844  0.07714844  0.07714844]\n",
      " [-0.45690918  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.05627441  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.20715332  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.3338623   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.32214355  0.07714844  0.07714844  0.07714844]\n",
      " [-0.0098877   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.05603027  0.07714844  0.07714844  0.07714844]\n",
      " [-0.430542    0.07714844  0.07714844  0.07714844]\n",
      " [ 0.27197266  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.42163086  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.15771484  0.07714844  0.07714844  0.07714844]\n",
      " [-0.00793457  0.07714844  0.07714844  0.07714844]\n",
      " [-0.3043213   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.2475586   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.04333496  0.07714844  0.07714844  0.07714844]\n",
      " [-0.20861816  0.07714844  0.07714844  0.07714844]\n",
      " [-0.32922363  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.37634277  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.46240234  0.11340332  0.07714844  0.07714844]\n",
      " [ 0.45288086  0.21569824  0.07714844  0.07714844]\n",
      " [ 0.19641113  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.05065918  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.3770752   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.45617676  0.07714844  0.07714844  0.07714844]\n",
      " [-0.04272461  0.07714844  0.07714844  0.07714844]\n",
      " [-0.13061523  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.33496094  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.00634766  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.18054199  0.07714844  0.07714844  0.07714844]\n",
      " [-0.27453613  0.07714844  0.07714844  0.07714844]\n",
      " [-0.00488281  0.07714844  0.07714844  0.07714844]\n",
      " [-0.11962891  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.05407715  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.31298828  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.27490234  0.07714844  0.07714844  0.07714844]\n",
      " [-0.27783203  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.13098145  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.1628418   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.22668457  0.07714844  0.07714844  0.07714844]\n",
      " [-0.0513916   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.0213623   0.07714844  0.07714844  0.07714844]\n",
      " [-0.18933105  0.07714844  0.07714844  0.07714844]\n",
      " [-0.40698242  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.08239746  0.07714844  0.07714844  0.07714844]\n",
      " [-0.46704102 -0.46936035  0.07714844  0.07714844]\n",
      " [ 0.07189941  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.06201172  0.07714844  0.07714844  0.07714844]\n",
      " [-0.18457031  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.09545898  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.42126465  0.4588623   0.07714844  0.07714844]\n",
      " [ 0.03015137  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.0559082   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.3922119   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.09606934  0.07714844  0.07714844  0.07714844]\n",
      " [-0.31066895  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.11621094  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.17224121  0.30847168  0.07714844  0.07714844]\n",
      " [-0.19726562  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.07006836  0.3980713   0.07714844  0.07714844]\n",
      " [ 0.37927246  0.07714844  0.07714844  0.07714844]\n",
      " [ 0.05114746 -0.2965088   0.07714844  0.07714844]\n",
      " [-0.40441895  0.26708984 -0.40112305  0.07714844]\n",
      " [ 0.29736328  0.07714844  0.07714844  0.07714844]\n",
      " [-0.30737305  0.07714844  0.07714844  0.07714844]\n",
      " [-0.3795166   0.07714844  0.07714844  0.07714844]\n",
      " [-0.02661133  0.07714844  0.07714844  0.07714844]\n",
      " [-0.1907959   0.07714844  0.07714844  0.07714844]\n",
      " [ 0.10351562  0.07714844  0.07714844  0.07714844]\n",
      " [-0.4215088   0.07714844  0.07714844  0.07714844]]\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "# outputs should be a tuple of size 4: trk_feat, trk_seg, passed, y_pred\n",
    "outputs_0, outputs_1, outputs_2, outputs_3 = outputs\n",
    "print(outputs_0, outputs_1, np.squeeze(outputs_2), np.squeeze(outputs_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fc438a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[999999 999999     16      0      4     66     20     20      1 999999\n",
      " 999999 999999 999999 999999      0      0      0     -5      5     -1\n",
      "      3 999999 999999 999999 999999 999999     -4      0      0 999999\n",
      " 999999 999999      6      6      6 999999   -816     61     61      0]\n",
      "[230 230  44  60  78 116 152 170 188 230 230 230]\n",
      "[   -87 999999     16     64     72 999999 999999     73 999999 999999\n",
      "      8   -141      2 999999      2      2      2 999999 999999      2\n",
      " 999999 999999      0      5      0 999999      4      4      0     10\n",
      "      6 999999      6      6      6      5   -960      7     63      0]\n",
      "[  0 230  36  54  72 230 230 162 230 230 144 216]\n",
      "[999999    -52     16     20     13    -41      6     15      6 999999\n",
      " 999999 999999 999999      2      1      0      0     -5      5     -1\n",
      "      3 999999 999999 999999 999999      4      0      0      0 999999\n",
      " 999999      6      6      6      6 999999   1936     61     63      0]\n",
      "[230  28  52  70  88 136 160 178 196 230 230 230]\n",
      "[   -98 999999      8     24 999999 999999 999999     29     25   -112\n",
      "      5 999999     -1 999999      0      0 999999 999999 999999      0\n",
      "      1      1      1 999999      4 999999      0      0 999999 999999\n",
      "      6 999999      6      6 999999 999999   1936     34     63      0]\n",
      "[ 22 230  40  58 230 230 230 166 196 130 148 230]\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "print(outputs_0[0, 0, :])\n",
    "print(outputs_1[0, 0, :])\n",
    "print(outputs_0[1, 0, :])\n",
    "print(outputs_1[1, 0, :])\n",
    "print(outputs_0[2, 0, :])\n",
    "print(outputs_1[2, 0, :])\n",
    "print(outputs_0[3, 0, :])\n",
    "print(outputs_1[3, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "748124f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_layers = [\n",
    "  model.get_layer('zonemerging_0').output,\n",
    "  model.get_layer('trkbuilding_0').output,\n",
    "  model.get_layer('duperemoval_0').output,\n",
    "  model.get_layer('trainfilter_0').output,\n",
    "  model.get_layer('fullyconnect_0').output,\n",
    "]\n",
    "\n",
    "extractor = tf.keras.Model(inputs=model.inputs, outputs=extractor_layers)\n",
    "\n",
    "extracted = extractor.predict(x_test_1, workers=workers, use_multiprocessing=False)  # now wait...\n",
    "extracted = iter(extracted)\n",
    "extracted_zonemerging_0 = next(extracted)\n",
    "extracted_trkbuilding_0 = next(extracted)\n",
    "extracted_duperemoval_0 = next(extracted)\n",
    "extracted_trainfilter_0 = next(extracted)[1:]   # drop features array from tuple\n",
    "extracted_fullyconnect_0 = next(extracted)[1:]  # drop features array from tuple\n",
    "assert isinstance(extracted_fullyconnect_0, tuple) and (len(extracted_fullyconnect_0) == 1)\n",
    "\n",
    "#FIXME: hardcoded dequantizer\n",
    "extracted_fullyconnect_0 = (extracted_fullyconnect_0[0] * np.power(2., 13),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22c13b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "4 [(100, 4), (100, 4), (100, 4), (100, 4)]\n",
      "2 [(100, 4, 40), (100, 4, 12)]\n",
      "2 [(100, 4, 40), (100, 4, 12)]\n",
      "1 [(100, 4, 1)]\n",
      "1 [(100, 4, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Make testbench\n",
    "if maxevents != -1:\n",
    "  print(len(x_test_sparse_1))\n",
    "  print(len(extracted_zonemerging_0), [x.shape for x in extracted_zonemerging_0])\n",
    "  print(len(extracted_trkbuilding_0), [x.shape for x in extracted_trkbuilding_0])\n",
    "  print(len(extracted_duperemoval_0), [x.shape for x in extracted_duperemoval_0])\n",
    "  print(len(extracted_trainfilter_0), [x.shape for x in extracted_trainfilter_0])\n",
    "  print(len(extracted_fullyconnect_0), [x.shape for x in extracted_fullyconnect_0])\n",
    "\n",
    "  save_serializable_object = emtf_nnet.keras.utils.save_serializable_object\n",
    "  save_serializable_object(x_test_sparse_1, 'x_test_sparse.json')\n",
    "  save_serializable_object(extracted_zonemerging_0, 'extracted_zonemerging_0.json')\n",
    "  save_serializable_object(extracted_trkbuilding_0, 'extracted_trkbuilding_0.json')\n",
    "  save_serializable_object(extracted_duperemoval_0, 'extracted_duperemoval_0.json')\n",
    "  save_serializable_object(extracted_trainfilter_0, 'extracted_trainfilter_0.json')\n",
    "  save_serializable_object(extracted_fullyconnect_0, 'extracted_fullyconnect_0.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e13333",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2d28f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 0 ns, total: 11 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if maxevents == -1:\n",
    "  outputs = model.predict(datagen, workers=workers, use_multiprocessing=False)  # now wait...\n",
    "  if isinstance(outputs, tuple):\n",
    "    for i in range(len(outputs)):\n",
    "      logger.info('outputs: {}'.format((outputs[i].shape, outputs[i].dtype.name)))\n",
    "  else:\n",
    "    logger.info('outputs: {}'.format((outputs.shape, outputs.dtype.name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a050d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect features and truths for training\n",
    "if maxevents == -1:\n",
    "  features = outputs[0][:, 0, :]  # first track only\n",
    "  truths = sector_part\n",
    "\n",
    "  passed = outputs[2][:, 0, 0]  # first track only, squeeze last dim\n",
    "  features, truths = (x[passed] for x in (features, truths))  # 'passed' only\n",
    "  logger.info('features: {}'.format((features.shape, features.dtype.name)))\n",
    "  logger.info('truths: {}'.format((truths.shape, truths.dtype.name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56ba5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_fill_value():\n",
    "  return 999999\n",
    "\n",
    "\n",
    "def latticeplot():\n",
    "  ni, nj = (xdata.shape[1] + 5) // 6, 6\n",
    "  fig, axs = plt.subplots(ni, nj, figsize=(6, 6 * ni / nj))\n",
    "\n",
    "  for i in range(ni):\n",
    "    for j in range(nj):\n",
    "      ij = (i * nj) + j\n",
    "      if ij >= xdata.shape[1]:\n",
    "        break\n",
    "\n",
    "      if axs.ndim == 2:\n",
    "        ax = axs[i, j]\n",
    "      elif axs.ndim == 1:\n",
    "        ax = axs[j]\n",
    "      else:\n",
    "        ax = axs\n",
    "      ax.hist(xdata[:, ij][xmask[:, ij]], bins=32)\n",
    "      ax.set_xticklabels([])\n",
    "      ax.set_yticklabels([])\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c5dcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot features and truths\n",
    "if maxevents == -1:\n",
    "  xdata = features\n",
    "  xmask = (features != ma_fill_value())\n",
    "  latticeplot()\n",
    "\n",
    "  xdata = truths\n",
    "  xmask = np.isfinite(truths)\n",
    "  latticeplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93203bcc",
   "metadata": {},
   "source": [
    "### Make noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f93081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 0 ns, total: 11 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if maxevents == -1:\n",
    "  outputs = model.predict(datagen_noise, workers=workers, use_multiprocessing=False, steps=2000)  # now wait...\n",
    "  if isinstance(outputs, tuple):\n",
    "    for i in range(len(outputs)):\n",
    "      logger.info('outputs: {}'.format((outputs[i].shape, outputs[i].dtype.name)))\n",
    "  else:\n",
    "    logger.info('outputs: {}'.format((outputs.shape, outputs.dtype.name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "885b14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect noises for training\n",
    "if maxevents == -1:\n",
    "  num_emtf_sites = 12\n",
    "  # -3 is th_median index\n",
    "  # -2 is trk_qual index\n",
    "  # 12:24 are emtf_theta indices\n",
    "  passed_0 = (outputs[0][:, :, -3] != 0)\n",
    "  passed_1 = (outputs[0][:, :, -2] != 0)\n",
    "  passed_2 = (outputs[0][:, :, (num_emtf_sites * 1):(num_emtf_sites * 2)] != ma_fill_value()).any(axis=-1)\n",
    "  passed = passed_0 & passed_1 & passed_2\n",
    "  noises = outputs[0][passed]  # 'passed' only\n",
    "\n",
    "  # Shuffle\n",
    "  shuffle = True\n",
    "  if shuffle:\n",
    "    index_array = np.arange(noises.shape[0])\n",
    "    np.random.shuffle(index_array)\n",
    "    noises = noises[index_array]\n",
    "  logger.info('noises: {}'.format((noises.shape, noises.dtype.name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "842dc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot noises\n",
    "if maxevents == -1:\n",
    "  xdata = noises\n",
    "  xmask = (noises != ma_fill_value())\n",
    "  latticeplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47870f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "if maxevents == -1:\n",
    "  outfile = 'features.h5'\n",
    "  outdict = {\n",
    "    'features': da.from_array(features),\n",
    "    'truths': da.from_array(truths),\n",
    "    'noises': da.from_array(noises),\n",
    "  }\n",
    "  da.to_hdf5(outfile, outdict, compression='lzf')\n",
    "  logger.info('Wrote to {}'.format(outfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb64a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f82410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
